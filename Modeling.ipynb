{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "93be79a5-cf36-4484-9703-358fd368d7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.tree import export_text, DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "435f9157-c2ec-4845-98bf-1471bdbd7160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9661, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>url</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>body</th>\n",
       "      <th>created</th>\n",
       "      <th>date</th>\n",
       "      <th>abv_median</th>\n",
       "      <th>title_len</th>\n",
       "      <th>body_len</th>\n",
       "      <th>external_link</th>\n",
       "      <th>title_clean</th>\n",
       "      <th>stem_string</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In what condition would the atmosphere have to...</td>\n",
       "      <td>0</td>\n",
       "      <td>climatechange</td>\n",
       "      <td>https://www.reddit.com/r/climatechange/comment...</td>\n",
       "      <td>5</td>\n",
       "      <td>What is currently happening in Earth is it's ...</td>\n",
       "      <td>1.661955e+09</td>\n",
       "      <td>2022-08-31 14:10:44</td>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>in what condition would the atmosphere have to...</td>\n",
       "      <td>in what condit would the atmospher have to be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Has anyone here been personally affected by a ...</td>\n",
       "      <td>26</td>\n",
       "      <td>climatechange</td>\n",
       "      <td>https://www.reddit.com/r/climatechange/comment...</td>\n",
       "      <td>21</td>\n",
       "      <td>With what’s happened in Pakistan, ongoing wild...</td>\n",
       "      <td>1.661933e+09</td>\n",
       "      <td>2022-08-31 08:07:27</td>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "      <td>217</td>\n",
       "      <td>0</td>\n",
       "      <td>has anyone here been personally affected by a ...</td>\n",
       "      <td>ha anyon here been person affect by a major cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A prolonged and record heat wave builds over t...</td>\n",
       "      <td>54</td>\n",
       "      <td>climatechange</td>\n",
       "      <td>https://www.cnn.com/2022/08/30/weather/record-...</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1.661902e+09</td>\n",
       "      <td>2022-08-30 23:33:35</td>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>a prolonged and record heat wave builds over t...</td>\n",
       "      <td>a prolong and record heat wave build over the ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  score      subreddit  \\\n",
       "0  In what condition would the atmosphere have to...      0  climatechange   \n",
       "1  Has anyone here been personally affected by a ...     26  climatechange   \n",
       "2  A prolonged and record heat wave builds over t...     54  climatechange   \n",
       "\n",
       "                                                 url  num_comments  \\\n",
       "0  https://www.reddit.com/r/climatechange/comment...             5   \n",
       "1  https://www.reddit.com/r/climatechange/comment...            21   \n",
       "2  https://www.cnn.com/2022/08/30/weather/record-...            10   \n",
       "\n",
       "                                                body       created  \\\n",
       "0   What is currently happening in Earth is it's ...  1.661955e+09   \n",
       "1  With what’s happened in Pakistan, ongoing wild...  1.661933e+09   \n",
       "2                                                  0  1.661902e+09   \n",
       "\n",
       "                  date  abv_median  title_len  body_len  external_link  \\\n",
       "0  2022-08-31 14:10:44           0         91       195              0   \n",
       "1  2022-08-31 08:07:27           1         69       217              0   \n",
       "2  2022-08-30 23:33:35           1         69         1              1   \n",
       "\n",
       "                                         title_clean  \\\n",
       "0  in what condition would the atmosphere have to...   \n",
       "1  has anyone here been personally affected by a ...   \n",
       "2  a prolonged and record heat wave builds over t...   \n",
       "\n",
       "                                         stem_string  \n",
       "0  in what condit would the atmospher have to be ...  \n",
       "1  ha anyon here been person affect by a major cl...  \n",
       "2  a prolong and record heat wave build over the ...  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_title = pd.read_csv('./data/cleaned_data.csv')\n",
    "print(cleaned_title.shape)\n",
    "cleaned_title.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "08fe09ef-03ba-47c2-9188-2865cdfd0b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title            0\n",
       "score            0\n",
       "subreddit        0\n",
       "url              0\n",
       "num_comments     0\n",
       "body             0\n",
       "created          0\n",
       "date             0\n",
       "abv_median       0\n",
       "title_len        0\n",
       "body_len         0\n",
       "external_link    0\n",
       "title_clean      3\n",
       "stem_string      3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_title.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3480f132-3c6a-4cf5-ae3e-0fb99054f19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping null values in 'title_clean'\n",
    "i = cleaned_title[(cleaned_title.title_clean.isnull())].index\n",
    "cleaned_title.drop(i, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f2247eb3-d1b0-4b00-aea0-70a1660e7ebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title            0\n",
       "score            0\n",
       "subreddit        0\n",
       "url              0\n",
       "num_comments     0\n",
       "body             0\n",
       "created          0\n",
       "date             0\n",
       "abv_median       0\n",
       "title_len        0\n",
       "body_len         0\n",
       "external_link    0\n",
       "title_clean      0\n",
       "stem_string      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_title.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53085b96-135a-4cc3-bb17-a8a5c53ba489",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Modeling:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164d80b4-ddef-4e17-b859-cb3618a801d4",
   "metadata": {},
   "source": [
    "## Title text:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f64c6a-d8b9-493b-8f78-25363f64852a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### CountVectorizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ba97ce8c-7efe-493c-ae6c-6ef0a4857667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_forest_params = {\n",
    "#     'max_depth' : [None, 5, 10],\n",
    "#     'min_samples_leaf': [2, 3, 5],\n",
    "#     'n_estimators': [100, 125, 150]\n",
    "    \n",
    "# }\n",
    "\n",
    "# gs = GridSearchCV(\n",
    "#     RandomForestClassifier(), param_grid=random_forest_params, verbose=1)\n",
    "\n",
    "# gs.fit(X_train_cv, y_train)\n",
    "\n",
    "# print(gs.best_score_, gs.best_params_)\n",
    "\n",
    "# gs.score(X_train_cv, y_train), gs.score(X_test_cv, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7b2663-2609-494c-8978-70af37080ad3",
   "metadata": {},
   "source": [
    "**results** from Gridsearch: Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
    "\n",
    "0.5822045152722444 {'max_depth': None, 'min_samples_leaf': 3, 'n_estimators': 100}\n",
    "\n",
    "(0.7698539176626826, 0.5828685258964144)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "27aae52e-90f1-4cff-a8ba-3f8c9948b492",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cleaned_title['stem_string']\n",
    "y = cleaned_title['abv_median']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, train_size=.75, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "398c16dc-a5eb-48a6-ba55-57197ddfa1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv = CountVectorizer(stop_words='english', binary=True, ngram_range=(1,2))\n",
    "cv= CountVectorizer()\n",
    "cv.fit(X_train)\n",
    "\n",
    "X_train_cv = cv.transform(X_train)\n",
    "X_test_cv = cv.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a2e9965d-950e-4fac-aa11-3f1a79491829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.995858069860555, 0.553623188405797)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier(random_state=42)\n",
    "dtc.fit(X_train_cv, y_train)\n",
    "dtc.score(X_train_cv, y_train), dtc.score(X_test_cv, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2a05e772-d057-4306-bc22-00f5dac3374f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7640480463896175, 0.6037267080745342)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(random_state=42, min_samples_leaf=3, n_estimators=150)\n",
    "rfc.fit(X_train_cv, y_train)\n",
    "rfc.score(X_train_cv, y_train), rfc.score(X_test_cv, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "94f4971e-10d4-48e6-9e91-d3a2a175ecc7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6584288278337705, 0.5991718426501035)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc = AdaBoostClassifier(random_state=42, n_estimators=150)\n",
    "\n",
    "abc.fit(X_train_cv, y_train)\n",
    "abc.score(X_train_cv, y_train), abc.score(X_test_cv, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30325f5-09bd-4b31-abef-fb9600f5612f",
   "metadata": {},
   "source": [
    "scores from text_clean, ngram_range(1,2)\n",
    "\n",
    "* DTC: .996 .531\n",
    "* RFC: .765 .598\n",
    "* ABC: .676 .603\n",
    "\n",
    "scores from text_clean, stop_words='english', binary=True, ngram_range=(1,2):\n",
    "\n",
    "* DTC: .993 .558\n",
    "* RFC: .756 .580\n",
    "* ABC: .646 .555\n",
    "\n",
    "scores from stem_string, all default:\n",
    "\n",
    "* DTC: .996 .549\n",
    "* RFC: .765 .604\n",
    "* ABC: .670 .600\n",
    "\n",
    "scores from stem_string, ngram_range=(1,2)\n",
    "\n",
    "* DTC: .996 .548\n",
    "* RFC: .770 .609\n",
    "* ABC: .674 .596"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "00cba371-5b97-480b-ac1b-0b9ef2b68e8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9866077592157946, 0.5900621118012422)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('cv', CountVectorizer(ngram_range=(1,2))),\n",
    "    ('lr', LogisticRegression(max_iter=1000)),\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "pipe.score(X_train, y_train), pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d18fe3a-c1e3-4207-8a7b-7335fb0abe13",
   "metadata": {},
   "source": [
    "### TfidVectorizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f2219470-aef7-4c12-9a66-6a8ad47a62fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = data_clean['title_clean']\n",
    "# y = data_clean['abv_median']\n",
    "\n",
    "X = cleaned_title['stem_string']\n",
    "y = cleaned_title['abv_median']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, train_size=.75, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9eba359d-1d45-409b-8a1c-e88b92fa8efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer(ngram_range=(1,2)) #stop_words=\"english\", \n",
    "\n",
    "# fit & transform\n",
    "tf.fit(X_train)\n",
    "X_train_tf = tf.transform(X_train)\n",
    "X_test_tf = tf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e148639f-a6e0-4dff-84b1-07511c714bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_tf = pd.DataFrame(X_train_tf.A, columns=tf.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "98fe8c6a-c3c8-49cd-a2d5-078b0b9121b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7243, 46565)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "726cad39-3e4d-4810-a0b1-fab7243c4935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "peak but        0.137683\n",
       "declin the      0.137683\n",
       "climat will     0.137683\n",
       "peak when       0.137683\n",
       "start declin    0.137683\n",
       "dtype: float64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_tf.sum().sort_values().head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1d3c6b55-a5ea-4049-8d2c-5ff5d9c1044f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "to              150.790458\n",
       "climat chang    180.517322\n",
       "chang           189.651072\n",
       "the             192.111240\n",
       "climat          210.027476\n",
       "dtype: float64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_tf.sum().sort_values().tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7a7524e9-0d1f-445a-ad43-ddac7cba6159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.995858069860555, 0.5469979296066253)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier(random_state=42)\n",
    "dtc.fit(X_train_tf, y_train)\n",
    "dtc.score(X_train_tf, y_train), dtc.score(X_test_tf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "cac40c02-37f9-4a8b-90d5-4feac45c72b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8290763495789037, 0.5763975155279503)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(random_state=42, min_samples_leaf=3, n_estimators=150)\n",
    "rfc.fit(X_train_tf, y_train)\n",
    "rfc.score(X_train_tf, y_train), rfc.score(X_test_tf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d49362f5-cc82-40d4-b60f-78e069e84fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6882507248377744, 0.5797101449275363)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc = AdaBoostClassifier(random_state=42, n_estimators=150)\n",
    "\n",
    "abc.fit(X_train_tf, y_train)\n",
    "abc.score(X_train_tf, y_train), abc.score(X_test_tf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "98c45e4d-8da7-43e5-b2ce-b3f0cbb12b90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
       "                ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspiration from: https://towardsdatascience.com/multi-class-text-classification-model-comparison-and-selection-5eb066197568\n",
    "X = cleaned_title['stem_string']\n",
    "y = cleaned_title['abv_median']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, train_size=.75, random_state=42)\n",
    "\n",
    "nb = Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ])\n",
    "nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "f8d87dae-5941-43f4-99e2-894b00db3555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.5937888198757764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.59      0.60      1267\n",
      "           1       0.57      0.60      0.58      1148\n",
      "\n",
      "    accuracy                           0.59      2415\n",
      "   macro avg       0.59      0.59      0.59      2415\n",
      "weighted avg       0.59      0.59      0.59      2415\n",
      "\n",
      "CPU times: user 31.8 ms, sys: 2.03 ms, total: 33.9 ms\n",
      "Wall time: 32.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "03f10eb2-e9ce-4922-a82a-18ca52644617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
       "                ('clf', LogisticRegression(max_iter=200, n_jobs=1))])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', LogisticRegression(max_iter=200, n_jobs=1)),\n",
    "               ])\n",
    "\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "8110faf8-698c-4f04-8d6a-daa127e7e93c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7690183625569516, 0.6037267080745342)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.score(X_train, y_train), logreg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "a5d84ec1-fea2-40e2-aff9-8818f84e2e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.6037267080745342\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.65      0.63      1267\n",
      "           1       0.59      0.55      0.57      1148\n",
      "\n",
      "    accuracy                           0.60      2415\n",
      "   macro avg       0.60      0.60      0.60      2415\n",
      "weighted avg       0.60      0.60      0.60      2415\n",
      "\n",
      "CPU times: user 34 ms, sys: 4.06 ms, total: 38 ms\n",
      "Wall time: 41.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "c27b2717-2385-4ed6-8c13-810ed0889ade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7640480463896175, 0.6037267080745342)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(random_state=42, min_samples_leaf=3, n_estimators=150)\n",
    "rfc.fit(X_train_cv, y_train)\n",
    "rfc.score(X_train_cv, y_train), rfc.score(X_test_cv, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd3a8db-803e-42f3-be19-be8ee1e3db90",
   "metadata": {},
   "source": [
    "## Other (non-text) Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b3dd5979-06bb-461d-97e2-6d5d0c11f965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'score', 'subreddit', 'url', 'num_comments', 'body', 'created',\n",
       "       'date', 'abv_median', 'title_len', 'body_len', 'external_link',\n",
       "       'title_clean', 'stem_string'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_title.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f6df720e-5ac0-4478-9a68-74c708a4f588",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['score', 'title_len', 'body_len', 'external_link']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "2a155b4e-4f53-4584-9838-a20628e3913a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cleaned_title[features]\n",
    "y = cleaned_title['abv_median']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.75, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "4a9f268d-22d5-4561-8c4e-570013eaf436",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "feat_logreg = Pipeline([('ss', StandardScaler()),\n",
    "                ('pf', PolynomialFeatures(include_bias=True)),\n",
    "                ('lr', LogisticRegression(max_iter=200, n_jobs=1)),\n",
    "               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "8b153ef1-0cce-4032-8bf2-6224c0226084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6487643241750656, 0.6140786749482402)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_logreg.fit(X_train, y_train)\n",
    "feat_logreg.score(X_train, y_train), feat_logreg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "266a22fb-1709-4cb1-8ce6-327f7e2c4ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.6140786749482402\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.70      0.65      1252\n",
      "           1       0.62      0.52      0.56      1163\n",
      "\n",
      "    accuracy                           0.61      2415\n",
      "   macro avg       0.61      0.61      0.61      2415\n",
      "weighted avg       0.61      0.61      0.61      2415\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = feat_logreg.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239c1119-288a-466f-9349-28899d46ce95",
   "metadata": {},
   "source": [
    "## Text AND other features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "7b781a24-5992-4b06-ba43-544b12182ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "numeric_features = ['title_len', 'body_len', 'score', 'external_link']\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[(\"scaler\", StandardScaler())]\n",
    ")\n",
    "\n",
    "text_features = ['stem_string']\n",
    "text_transformer = Pipeline(\n",
    "    steps=[('vect', CountVectorizer(ngram_range=(1,2))),\n",
    "                ('tfidf', TfidfTransformer())]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"text\", text_transformer, text_features),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "8dfc9bf5-ee3a-4061-a8cb-64fb019da4a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 7243 and the array at index 1 has size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [153]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m y \u001b[38;5;241m=\u001b[39m cleaned_title[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mabv_median\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      8\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, train_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m.75\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel score: \u001b[39m\u001b[38;5;132;01m%.3f\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m clf\u001b[38;5;241m.\u001b[39mscore(X_test, y_test))\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py:390\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;124;03m\"\"\"Fit the model.\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03mFit all the transformers one after the other and transform the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;124;03m    Pipeline with fitted steps.\u001b[39;00m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    389\u001b[0m fit_params_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_fit_params(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m--> 390\u001b[0m Xt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py:348\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[0;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[1;32m    346\u001b[0m     cloned_transformer \u001b[38;5;241m=\u001b[39m clone(transformer)\n\u001b[1;32m    347\u001b[0m \u001b[38;5;66;03m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[0;32m--> 348\u001b[0m X, fitted_transformer \u001b[38;5;241m=\u001b[39m \u001b[43mfit_transform_one_cached\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcloned_transformer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPipeline\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_steps\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;66;03m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;66;03m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;66;03m# from the cache.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[step_idx] \u001b[38;5;241m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/memory.py:349\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py:893\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    891\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[1;32m    892\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 893\u001b[0m         res \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    894\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    895\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/compose/_column_transformer.py:699\u001b[0m, in \u001b[0;36mColumnTransformer.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_output(Xs)\n\u001b[1;32m    697\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_record_output_indices(Xs)\n\u001b[0;32m--> 699\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_hstack\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mXs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/compose/_column_transformer.py:791\u001b[0m, in \u001b[0;36mColumnTransformer._hstack\u001b[0;34m(self, Xs)\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    790\u001b[0m     Xs \u001b[38;5;241m=\u001b[39m [f\u001b[38;5;241m.\u001b[39mtoarray() \u001b[38;5;28;01mif\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(f) \u001b[38;5;28;01melse\u001b[39;00m f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m Xs]\n\u001b[0;32m--> 791\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mhstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/numpy/core/shape_base.py:345\u001b[0m, in \u001b[0;36mhstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _nx\u001b[38;5;241m.\u001b[39mconcatenate(arrs, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    344\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_nx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 7243 and the array at index 1 has size 1"
     ]
    }
   ],
   "source": [
    "clf = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor), (\"classifier\", LogisticRegression(max_iter=200))]\n",
    ")\n",
    "\n",
    "X = cleaned_title[['title_len', 'body_len', 'score', 'external_link', 'stem_string']]\n",
    "y = cleaned_title['abv_median']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.75, random_state=42)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"model score: %.3f\" % clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35c887a-0cb1-4e56-b0b3-4e451a4c7c13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
